{
  "optimizer": "adam",
  "learning_rate": 0.0001,
  "batch_size": 32,
  "use_gradient_clipping": true,
  "gradient_clipping_value": 50.0
}